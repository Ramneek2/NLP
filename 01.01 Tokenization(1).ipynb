{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy scikit-learn plotly\n",
    "%pip install --no-cache-dir --force-reinstall https://dm.cs.tu-dortmund.de/nats/nats25_01_01_tokenization-0.1-py3-none-any.whl\n",
    "import nats25_01_01_tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c2563",
   "metadata": {},
   "source": [
    "# Foundations\n",
    "## Basic text data processing\n",
    "\n",
    "In this assignment, you will practise some basic text data processing skills, and get to explore a data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a927fd",
   "metadata": {},
   "source": [
    "### Load and tokenize the Hamlet data set\n",
    "\n",
    "Load the Hamlet data set, and tokenize it into suitable words (omit punctuation!).\n",
    "\n",
    "You may choose a very basic tokenization approach, such as the one from the lecture introduction (despite its limitations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe1718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, urllib\n",
    "\n",
    "# You can add some setup code here (e.g., re.compile)\n",
    "pass # Your solution here\n",
    "\n",
    "tokenized = list() # Store your output in this list\n",
    "file_path, _ = urllib.request.urlretrieve(\"https://dm.cs.tu-dortmund.de/nats/data/hamlet.txt\")\n",
    "for line in open(file_path, \"rt\"):\n",
    "    \"\"\"Process the Hamlet data line by line\"\"\"\n",
    "    pass # Your solution here\n",
    "\n",
    "print(f\"Hamlet contains {len(tokenized)} words total, {len(set(tokenized))} unique.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f5a99d",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nats25_01_01_tokenization.hidden_tests_3_0(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bcc542",
   "metadata": {},
   "source": [
    "### Find the most common words in the corpus\n",
    "\n",
    "Find the 20 most common words in the corpus.\n",
    "\n",
    "Store them along with the counts in the variable `most_common`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab87728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter # you will find this class useful\n",
    "most_common = [] # store your output in this variable\n",
    "\n",
    "pass # Your solution here\n",
    "\n",
    "# Print the most common words:\n",
    "for word, count in most_common: print(word, count, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abecc09",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nats25_01_01_tokenization.hidden_tests_6_0(most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2557ef88",
   "metadata": {},
   "source": [
    "### Remove English Stopwords\n",
    "\n",
    "Load the file `english-stopwords.txt` and remove the stop words from the token list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b869458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens=[] # Store your solution here\n",
    "stopword_file, _ = urllib.request.urlretrieve(\"https://dm.cs.tu-dortmund.de/nats/data/english-stopwords.txt\")\n",
    "\n",
    "pass # Your solution here\n",
    "\n",
    "print(\"Number of stopwords:\", len(stopwords))\n",
    "print(\"Size before removing:\", len(tokenized))\n",
    "print(\"Size after removing stopwords:\", len(filtered_tokens))\n",
    "print(\"Unique words before: %d and after: %d\" % (len(set(tokenized)), len(set(filtered_tokens))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2691b2",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nats25_01_01_tokenization.hidden_tests_9_0(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77e6748",
   "metadata": {},
   "source": [
    "### Find the most frequent words after stopword removal\n",
    "\n",
    "Find the 20 most common words in the filtered text.\n",
    "\n",
    "Store them along with the counts in the variable `filtered_most_common`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter # you will find this class useful\n",
    "filtered_most_common = [] # store your answer here\n",
    "\n",
    "pass # Your solution here\n",
    "\n",
    "# Print the most common words:\n",
    "for word, count in filtered_most_common: print(word, count, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c021b6",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nats25_01_01_tokenization.hidden_tests_12_0(filtered_most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52c9feb",
   "metadata": {},
   "source": [
    "### Make a frequency plot of the most common 100 words\n",
    "\n",
    "Explore Zipf's law by plotting the frequencies of the 100 most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "values, labels = [], [] # store your data here\n",
    "\n",
    "pass # Your solution here\n",
    "\n",
    "# Visualize the data\n",
    "# Note: You may need to zoom in to see all labels on the x axis\n",
    "go.Figure(go.Scatter(\n",
    "\tx=labels,\n",
    "\ty=values,\n",
    "\tmode=\"lines\",\n",
    ")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21360b3",
   "metadata": {},
   "source": [
    "### Log-log Plot\n",
    "\n",
    "Plot the word frequencies, sorted descendingly, in log-log-space.\n",
    "The plot should be reasonably approximated by a straight line in the log-log-plot, as seen in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4290ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Also plot original data in logspace, this should look approximately linear\n",
    "values = None # Store your data here\n",
    "values_fit = None # Store the linear fit in log-log-space here\n",
    "\n",
    "# Compute values\n",
    "pass # Your solution here\n",
    "\n",
    "X = np.arange(len(values)) + 1 # x coordinates for fitting and plotting\n",
    "# Linear fit\n",
    "pass # Your solution here\n",
    "\n",
    "go.Figure(\n",
    "\t[\n",
    "\t\tgo.Scatter(x=X,y=values,mode=\"lines\",name=\"Original data\"),\n",
    "\t\tgo.Scatter(x=X,y=values_fit,mode=\"lines\",name=\"Fit\"),\n",
    "\t],\n",
    "\tlayout_xaxis_type=\"log\",\n",
    "\tlayout_yaxis_type=\"log\",\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ea812",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nats25_01_01_tokenization.hidden_tests_17_0(values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
