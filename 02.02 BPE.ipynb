{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7d7c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ramneek/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages (2.2.5)\n",
      "Requirement already satisfied: numba in /home/ramneek/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages (0.61.2)\n",
      "Requirement already satisfied: tqdm in /home/ramneek/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /home/ramneek/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/ramneek/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages (from numba) (0.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ramneek/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ramneek/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ramneek/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ramneek/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting nats25-02-02-bpe==0.1\n",
      "  Downloading https://dm.cs.tu-dortmund.de/nats/nats25_02_02_bpe-0.1-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: nats25-02-02-bpe\n",
      "  Attempting uninstall: nats25-02-02-bpe\n",
      "    Found existing installation: nats25_02_02_bpe 0.1\n",
      "    Uninstalling nats25_02_02_bpe-0.1:\n",
      "      Successfully uninstalled nats25_02_02_bpe-0.1\n",
      "Successfully installed nats25-02-02-bpe-0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy numba tqdm pandas\n",
    "%pip install --no-cache-dir --force-reinstall https://dm.cs.tu-dortmund.de/nats/nats25_02_02_bpe-0.1-py3-none-any.whl\n",
    "import nats25_02_02_bpe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe56cc",
   "metadata": {},
   "source": [
    "# Byte-Pair Encoding\n",
    "\n",
    "In this assignment, your task is to implement the training of a byte-pair-encoding tokenizer yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9993be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, re\n",
    "from numba import jit\n",
    "try: from tqdm.notebook import tqdm # optional\n",
    "except: tqdm = None\n",
    "\n",
    "# Load the input data\n",
    "import gzip, json, urllib\n",
    "file_path, _ = urllib.request.urlretrieve(\"https://dm.cs.tu-dortmund.de/nats/data/minecraft-articles.json.gz\")\n",
    "raw = json.load(gzip.open(file_path, \"rt\", encoding=\"utf-8\"))\n",
    "titles, texts, classes = [x[\"title\"] for x in raw], [x[\"text\"] for x in raw], [x[\"heuristic\"] for x in raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74089f6",
   "metadata": {},
   "source": [
    "## Join texts into a single sequence of bytes.\n",
    "\n",
    "Split all the provided texts (`title` and `text`) using the given whitespace pretokenizer. Encode the tokens as bytes with UTF-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d02c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714539\n"
     ]
    }
   ],
   "source": [
    "#in this we tokenized the titles and texts into one singular data array where each element is a byte represenation of each token \n",
    "pretokenizer=re.compile(r\"\\n|\\s*\\S+\")\n",
    "data = []\n",
    "for title in titles:\n",
    "    split_text = pretokenizer.findall(string=title)\n",
    "    for elm in split_text:\n",
    "        data.append(elm)\n",
    "\n",
    "for text in texts: \n",
    "    split_text = pretokenizer.findall(string=text)\n",
    "    for elm in split_text:\n",
    "        data.append(elm)\n",
    "for index in range(0,len(data)): \n",
    "    data[index] = data[index].encode(encoding=\"utf-8\")\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e4effe9",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nats25_02_02_bpe.hidden_tests_4_0(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb38712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4649344,)\n"
     ]
    }
   ],
   "source": [
    "# In the following, we will use lists containing numpy arrays with int16\n",
    "data = np.array([int(x) for x in b\"\\0\".join(data)], dtype=np.int16)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab2a8ec",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nats25_02_02_bpe.hidden_tests_6_0(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d223075e",
   "metadata": {},
   "source": [
    "## Write a function to find the most common two symbols in a sequence\n",
    "\n",
    "While this will be the performance bottleneck of the implementation, you may use a `Counter` of pairs here.\n",
    "\n",
    "In our experiments, a vectorized numpy solution was 60x faster.\n",
    "\n",
    "- Return a pair of ints (we *will* exceed the byte range).\n",
    "- Skip 0 tokens used as separators\n",
    "- The second token must not be a space or newline (\"pre-tokenization\")\n",
    "- When no token occurs more than once, return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b0d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def find_most_frequent(seq):\n",
    "    if len(seq) < 2:\n",
    "        return None\n",
    "\n",
    "    # Create a 2D array of all adjacent pairs\n",
    "    pairs = np.stack([seq[:-1], seq[1:]], axis=1)\n",
    "\n",
    "    # Define a mask to filter out invalid pairs\n",
    "    # 1. The first token cannot be the separator (0).\n",
    "    # 2. The second token cannot be a space (32) or a newline (10).\n",
    "    mask = (seq[:-1] != 0) & (seq[1:] != 32) & (seq[1:] != 10)\n",
    "\n",
    "    # Apply the mask to get only valid pairs\n",
    "    valid_pairs = pairs[mask]\n",
    "\n",
    "    if valid_pairs.shape[0] == 0:\n",
    "        return None\n",
    "\n",
    "    # Find unique pairs and their counts\n",
    "    unique_pairs, counts = np.unique(valid_pairs, axis=0, return_counts=True)\n",
    "\n",
    "    # If no pair occurs more than once, return None\n",
    "    max_count = counts.max()\n",
    "    if max_count <= 1:\n",
    "        return None\n",
    "\n",
    "    # Find and return the most frequent pair\n",
    "    most_frequent_pair = unique_pairs[np.argmax(counts)]\n",
    "    return tuple(most_frequent_pair.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cddb65e",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Function should return a tuple of np.int16",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAssertionError\u001b[39m: Function should return a tuple of np.int16"
     ]
    }
   ],
   "source": [
    "nats25_02_02_bpe.hidden_tests_9_0(find_most_frequent, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc7662",
   "metadata": {},
   "source": [
    "## Initialize the vocabulary\n",
    "\n",
    "Our initial vocabulary contains all 256 bytes, so we can later still encode any character (or byte sequence) not in our training data.\n",
    "The vocabulary is used for decoding, so it is a map from integer token ids to bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f853418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vocab():\n",
    "    vocab = dict() # int to bytes\n",
    "    pass # Your solution here\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76b58a77",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Vocabulary does not have 256 entries",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAssertionError\u001b[39m: Vocabulary does not have 256 entries"
     ]
    }
   ],
   "source": [
    "nats25_02_02_bpe.hidden_tests_12_0(init_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91bbaf7",
   "metadata": {},
   "source": [
    "## Token replacement function\n",
    "\n",
    "In the given sequence, replace tokens (a,b) with a new token c. Avoid copying, but modify the sequence in-place. You can use `numba.jit` to make this (much) faster.\n",
    "\n",
    "Return the resulting array (-view)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6de68c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(seq, a, b, c):\n",
    "    pass # Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f3c88fa",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[31mTypeError\u001b[39m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "nats25_02_02_bpe.hidden_tests_15_0(replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449f21d",
   "metadata": {},
   "source": [
    "## Train BPE\n",
    "\n",
    "Implement a function to train a byte-pair encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "443ff8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe(indata, size=1000):\n",
    "    merges = list() # of tuples(id1, id2)\n",
    "    vocab = init_vocab()\n",
    "    data = np.array(indata, dtype=np.int16) # copy to allow modifications\n",
    "    pbar = tqdm(total=size-256) if tqdm else None # optional\n",
    "\n",
    "    pass # Your solution here\n",
    "\n",
    "    if pbar: pbar.close() # finish progressbar\n",
    "    print(\"Compression factor:\", len(data) / len(indata))\n",
    "    return vocab, merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e29e01d",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtrain_bpe\u001b[39m\u001b[34m(indata, size)\u001b[39m\n\u001b[32m      3\u001b[39m vocab = init_vocab()\n\u001b[32m      4\u001b[39m data = np.array(indata, dtype=np.int16) \u001b[38;5;66;03m# copy to allow modifications\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m pbar = \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m tqdm \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# optional\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m \u001b[38;5;66;03m# Your solution here\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pbar: pbar.close() \u001b[38;5;66;03m# finish progressbar\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages/tqdm/notebook.py:234\u001b[39m, in \u001b[36mtqdm_notebook.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m unit_scale = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    233\u001b[39m total = \u001b[38;5;28mself\u001b[39m.total * unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28mself\u001b[39m.container = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m.container.pbar = proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.displayed = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages/tqdm/notebook.py:108\u001b[39m, in \u001b[36mtqdm_notebook.status_printer\u001b[39m\u001b[34m(_, total, desc, ncols)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[32m    110\u001b[39m     pbar = IProgress(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m=total)\n",
      "\u001b[31mImportError\u001b[39m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "nats25_02_02_bpe.hidden_tests_18_0(train_bpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c00ec66",
   "metadata": {},
   "source": [
    "## Train a tokenizer on our training data\n",
    "\n",
    "Inspect the longest tokens generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62fc3547",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtrain_bpe\u001b[39m\u001b[34m(indata, size)\u001b[39m\n\u001b[32m      3\u001b[39m vocab = init_vocab()\n\u001b[32m      4\u001b[39m data = np.array(indata, dtype=np.int16) \u001b[38;5;66;03m# copy to allow modifications\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m pbar = \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m tqdm \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# optional\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m \u001b[38;5;66;03m# Your solution here\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pbar: pbar.close() \u001b[38;5;66;03m# finish progressbar\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages/tqdm/notebook.py:234\u001b[39m, in \u001b[36mtqdm_notebook.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m unit_scale = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    233\u001b[39m total = \u001b[38;5;28mself\u001b[39m.total * unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28mself\u001b[39m.container = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m.container.pbar = proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.displayed = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/prak_opt_env_conda/lib/python3.13/site-packages/tqdm/notebook.py:108\u001b[39m, in \u001b[36mtqdm_notebook.status_printer\u001b[39m\u001b[34m(_, total, desc, ncols)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[32m    110\u001b[39m     pbar = IProgress(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m=total)\n",
      "\u001b[31mImportError\u001b[39m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab, merges = train_bpe(data, 1024) # begin with 512 â€“ at 1024, we get many more words as standalone tokens, but the runtime increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "272a8695",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m nats25_02_02_bpe.hidden_tests_21_0(\u001b[43mvocab\u001b[49m, merges)\n",
      "\u001b[31mNameError\u001b[39m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "nats25_02_02_bpe.hidden_tests_21_0(vocab, merges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724064bb",
   "metadata": {},
   "source": [
    "## Tokenization function\n",
    "\n",
    "Implement a function to tokenize a string given the vocabulary and merges.\n",
    "\n",
    "While not the most efficient, it is fine to implement this using `replace` above. To improve performance, call `replace` only when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80811ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(merges, s):\n",
    "    tokens = None # np.array of int16 as above\n",
    "    pass # Your solution here\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee2d8b",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nats25_02_02_bpe.hidden_tests_24_0(vocab, merges, tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf2e08b",
   "metadata": {},
   "source": [
    "## Decoding function\n",
    "\n",
    "Implement a function to decode a token sequence into a regular string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6455b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(vocab, tokens):\n",
    "    s = None\n",
    "    pass # Your solution here\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc142d6",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nats25_02_02_bpe.hidden_tests_27_0(vocab, merges, tokenize, decode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prak_opt_env_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
